{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend, layers, metrics\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the encoder model\n",
    "def get_encoder(input_shape):\n",
    "    \"\"\" Returns the image encoding model \"\"\"\n",
    "    encoder = Sequential([\n",
    "        # Create the encoder layers based on the summary you provided\n",
    "        tf.keras.applications.Xception(\n",
    "            input_shape=input_shape,\n",
    "            weights=None,  # Don't load weights here, will load saved weights later\n",
    "            include_top=False,\n",
    "            pooling='avg',\n",
    "        ),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n",
    "    ], name=\"Encode_Model\")\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the encoder model\n",
    "encoder_obj = get_encoder((128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x22bb2e2b650>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved weights into the encoder\n",
    "encoder_obj.load_weights(\"encoder_folder/encoder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction based on encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to preprocess and encode an image\n",
    "# def encode_image(image_path, encoder):\n",
    "#     # Load and preprocess the image\n",
    "#     image = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))\n",
    "#     image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "#     image = tf.keras.applications.xception.preprocess_input(image)\n",
    "#     image = tf.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "#     # Encode the image using the encoder\n",
    "#     encoded_image = encoder.predict(image)\n",
    "#     return encoded_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to compute the distance between two encoded images\n",
    "# def compute_distance(encoded_image1, encoded_image2):\n",
    "#     distance = tf.norm(encoded_image1 - encoded_image2, axis=1)\n",
    "#     return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "The images are similar.\n"
     ]
    }
   ],
   "source": [
    "# # Example usage:\n",
    "# image_path1 = \"dog_data\\\\5907\\\\5907_A_h-8AQKUCJ6wAAAAAAAAAAAAAAQAAAQ.jpg\"\n",
    "# image_path2 = \"dog_data\\\\5907\\\\5907_A_TKDrRJ6csBwAAAAAAAAAAAAAAQAAAQ.jpg\"\n",
    "\n",
    "# # Encode the images\n",
    "# encoded_image1 = encode_image(image_path1, encoder)\n",
    "# encoded_image2 = encode_image(image_path2, encoder)\n",
    "\n",
    "# # Compute the distance between the encoded images\n",
    "# distance = compute_distance(encoded_image1, encoded_image2)\n",
    "\n",
    "# # Threshold for deciding similarity\n",
    "# threshold = 0.8  # You may adjust this threshold based on your task\n",
    "\n",
    "# # Check if the distance is below the threshold\n",
    "# if distance < threshold:\n",
    "#     print(\"The images are of same Dog.\")\n",
    "# else:\n",
    "#     print(\"The images are not same of Same Dog.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "\n",
    "\n",
    "def get_siamese_network(encoder, input_shape = (128, 128, 3)):\n",
    "\n",
    "    # Input Layers for the images\n",
    "    anchor_input   = layers.Input(input_shape, name=\"Anchor_Input\")\n",
    "    positive_input = layers.Input(input_shape, name=\"Positive_Input\")\n",
    "    negative_input = layers.Input(input_shape, name=\"Negative_Input\")\n",
    "\n",
    "    ## Generate the encodings (feature vectors) for the images\n",
    "    encoded_a = encoder(anchor_input)\n",
    "    encoded_p = encoder(positive_input)\n",
    "    encoded_n = encoder(negative_input)\n",
    "\n",
    "    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n",
    "    distances = DistanceLayer()(\n",
    "        encoded_a,\n",
    "        encoded_p,\n",
    "        encoded_n\n",
    "    )\n",
    "    # Creating the Model\n",
    "    siamese_network = Model(\n",
    "        inputs  = [anchor_input, positive_input, negative_input],\n",
    "        outputs = distances,\n",
    "        name = \"Siamese_Network\"\n",
    "    )\n",
    "    return siamese_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Siamese_Network\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Anchor_Input (InputLayer)      [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Positive_Input (InputLayer)    [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Negative_Input (InputLayer)    [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Encode_Model (Sequential)      (None, 256)          22043944    ['Anchor_Input[0][0]',           \n",
      "                                                                  'Positive_Input[0][0]',         \n",
      "                                                                  'Negative_Input[0][0]']         \n",
      "                                                                                                  \n",
      " distance_layer (DistanceLayer)  ((None,),           0           ['Encode_Model[0][0]',           \n",
      "                                 (None,))                         'Encode_Model[1][0]',           \n",
      "                                                                  'Encode_Model[2][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,043,944\n",
      "Trainable params: 21,988,392\n",
      "Non-trainable params: 55,552\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_network = get_siamese_network(encoder=encoder_obj)\n",
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we'll define the SiameseModel class and create an instance of it:\n",
    "class SiameseModel(Model):\n",
    "    def __init__(self, siamese_network, margin=1.0):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.siamese_network = siamese_network\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.siamese_network.trainable_weights))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = SiameseModel(siamese_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x22bb25b8410>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_model.load_weights(\"siamese_model_folder/siamese_model-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Siamese_Network\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Anchor_Input (InputLayer)      [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Positive_Input (InputLayer)    [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Negative_Input (InputLayer)    [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Encode_Model (Sequential)      (None, 256)          22043944    ['Anchor_Input[0][0]',           \n",
      "                                                                  'Positive_Input[0][0]',         \n",
      "                                                                  'Negative_Input[0][0]']         \n",
      "                                                                                                  \n",
      " distance_layer (DistanceLayer)  ((None,),           0           ['Encode_Model[0][0]',           \n",
      "                                 (None,))                         'Encode_Model[1][0]',           \n",
      "                                                                  'Encode_Model[2][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,043,944\n",
      "Trainable params: 21,988,392\n",
      "Non-trainable params: 55,552\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess an image\n",
    "import cv2\n",
    "def load_image(image_path, target_size=(128, 128)):\n",
    "    # Load the image from the specified path\n",
    "    image = cv2.imread(image_path)\n",
    "    # Resize the image to the target size\n",
    "    image = cv2.resize(image, target_size)\n",
    "    # Convert the image from BGR to RGB format (OpenCV loads images in BGR format by default)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Normalize the image to the range [0, 1]\n",
    "    image = image / 255.0\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get predictions for new data pairs\n",
    "def predict_similarity(image_path1, image_path2):\n",
    "    # Load and preprocess the images\n",
    "    image1 = load_image(image_path1)\n",
    "    image2 = load_image(image_path2)\n",
    "    pair = np.array([image1, image2])\n",
    "\n",
    "    # Reshape the input pair to match the model's input shape\n",
    "    pair = np.expand_dims(pair, axis=0)\n",
    "\n",
    "    # Get the prediction from the model\n",
    "    predictions = siamese_model.predict([pair[:, 0], pair[:, 1], pair[:, 1]])\n",
    "\n",
    "    # Check if the distances are within a certain threshold to determine similarity\n",
    "    threshold = 0.5  # Adjust this threshold as needed\n",
    "    similarity = \"Similar\" if predictions[0] < threshold else \"Different\"\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 278ms/step\n",
      "Prediction: Similar\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "image1 = \"dog_data\\\\5959\\\\5959_A_lPwKS7HXTIUAAAAAAAAAAAAAAQAAAQ.jpg\"  # Load your image here\n",
    "image2 = \"dog_data\\\\5959\\\\5959_A_p1FURL5LiRoAAAAAAAAAAAAAAQAAAQ.jpg\" # Load your image here\n",
    "\n",
    "result = predict_similarity(image1, image2)\n",
    "print(\"Prediction:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
